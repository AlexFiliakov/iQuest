"""Comprehensive tests for ensemble detector and feedback processor."""

import pytest
from datetime import date, datetime, timedelta
from unittest.mock import Mock, patch, MagicMock
import pandas as pd
import numpy as np

from src.analytics.ensemble_detector import (
    EnsembleDetector, VotingStrategy, EnsembleConfig, DetectorWeight
)
from src.analytics.feedback_processor import (
    FeedbackProcessor, UserFeedback, FeedbackType, 
    FeedbackImpact, LearningUpdate
)


class TestEnsembleModels:
    """Test ensemble model classes."""
    
    def test_voting_strategy_enum(self):
        """Test VotingStrategy enumeration."""
        assert VotingStrategy.MAJORITY.value == "majority"
        assert VotingStrategy.WEIGHTED.value == "weighted"
        assert VotingStrategy.UNANIMOUS.value == "unanimous"
        assert VotingStrategy.THRESHOLD.value == "threshold"
        
    def test_ensemble_config_creation(self):
        """Test EnsembleConfig creation."""
        config = EnsembleConfig(
            voting_strategy=VotingStrategy.WEIGHTED,
            detector_weights={
                "anomaly_detector": 0.4,
                "trend_detector": 0.3,
                "pattern_detector": 0.3
            },
            confidence_threshold=0.7,
            min_detectors_agree=2
        )
        
        assert config.voting_strategy == VotingStrategy.WEIGHTED
        assert sum(config.detector_weights.values()) == 1.0
        assert config.confidence_threshold == 0.7
        
    def test_detector_weight_creation(self):
        """Test DetectorWeight creation."""
        weight = DetectorWeight(
            detector_name="anomaly_detector",
            base_weight=0.3,
            performance_score=0.85,
            adjusted_weight=0.34,
            recent_accuracy=[0.82, 0.85, 0.88]
        )
        
        assert weight.detector_name == "anomaly_detector"
        assert weight.performance_score == 0.85
        assert weight.adjusted_weight > weight.base_weight


class TestEnsembleDetector:
    """Test ensemble detector functionality."""
    
    @pytest.fixture
    def detectors(self):
        """Create mock detectors."""
        anomaly_detector = Mock()
        anomaly_detector.name = "anomaly_detector"
        anomaly_detector.detect = Mock()
        
        trend_detector = Mock()
        trend_detector.name = "trend_detector"
        trend_detector.detect = Mock()
        
        pattern_detector = Mock()
        pattern_detector.name = "pattern_detector"
        pattern_detector.detect = Mock()
        
        return {
            "anomaly": anomaly_detector,
            "trend": trend_detector,
            "pattern": pattern_detector
        }
    
    @pytest.fixture
    def ensemble(self, detectors):
        """Create ensemble detector."""
        config = EnsembleConfig(
            voting_strategy=VotingStrategy.WEIGHTED,
            detector_weights={
                "anomaly": 0.4,
                "trend": 0.35,
                "pattern": 0.25
            }
        )
        return EnsembleDetector(detectors=detectors, config=config)
    
    @pytest.fixture
    def sample_data(self):
        """Create sample health data."""
        dates = pd.date_range('2023-01-01', periods=30, freq='D')
        values = np.random.normal(8000, 1000, 30)
        # Add anomalies
        values[10] = 15000  # Spike
        values[20] = 2000   # Drop
        
        return pd.DataFrame({
            'date': dates,
            'value': values,
            'type': 'steps'
        })
    
    def test_ensemble_detection_majority_voting(self, detectors, sample_data):
        """Test ensemble detection with majority voting."""
        # Configure detector responses
        detectors['anomaly'].detect.return_value = [
            {"date": sample_data['date'].iloc[10], "type": "spike", "confidence": 0.9},
            {"date": sample_data['date'].iloc[20], "type": "drop", "confidence": 0.85}
        ]
        detectors['trend'].detect.return_value = [
            {"date": sample_data['date'].iloc[10], "type": "spike", "confidence": 0.8}
        ]
        detectors['pattern'].detect.return_value = [
            {"date": sample_data['date'].iloc[10], "type": "spike", "confidence": 0.7},
            {"date": sample_data['date'].iloc[20], "type": "drop", "confidence": 0.6}
        ]
        
        config = EnsembleConfig(voting_strategy=VotingStrategy.MAJORITY)
        ensemble = EnsembleDetector(detectors=detectors, config=config)
        
        results = ensemble.detect(sample_data)
        
        # All three detectors agree on day 10, two agree on day 20
        assert len(results) == 2
        assert any(r['date'] == sample_data['date'].iloc[10] for r in results)
        assert any(r['date'] == sample_data['date'].iloc[20] for r in results)
        
    def test_ensemble_detection_weighted_voting(self, ensemble, sample_data):
        """Test ensemble detection with weighted voting."""
        # Configure detector responses with different confidences
        ensemble.detectors['anomaly'].detect.return_value = [
            {"date": sample_data['date'].iloc[10], "type": "spike", "confidence": 0.95}
        ]
        ensemble.detectors['trend'].detect.return_value = [
            {"date": sample_data['date'].iloc[10], "type": "spike", "confidence": 0.6}
        ]
        ensemble.detectors['pattern'].detect.return_value = []
        
        results = ensemble.detect(sample_data)
        
        # Weighted confidence should exceed threshold
        assert len(results) > 0
        # Result confidence should be weighted average
        result = results[0]
        expected_confidence = (0.95 * 0.4 + 0.6 * 0.35) / (0.4 + 0.35)
        assert abs(result['ensemble_confidence'] - expected_confidence) < 0.01
        
    def test_ensemble_detection_unanimous(self, detectors, sample_data):
        """Test ensemble detection requiring unanimous agreement."""
        config = EnsembleConfig(voting_strategy=VotingStrategy.UNANIMOUS)
        ensemble = EnsembleDetector(detectors=detectors, config=config)
        
        # Only one detector finds something
        detectors['anomaly'].detect.return_value = [
            {"date": sample_data['date'].iloc[10], "type": "spike", "confidence": 0.9}
        ]
        detectors['trend'].detect.return_value = []
        detectors['pattern'].detect.return_value = []
        
        results = ensemble.detect(sample_data)
        
        # Should be empty since not unanimous
        assert len(results) == 0
        
        # All detectors agree
        for detector in detectors.values():
            detector.detect.return_value = [
                {"date": sample_data['date'].iloc[10], "type": "spike", "confidence": 0.8}
            ]
        
        results = ensemble.detect(sample_data)
        
        # Should find the anomaly
        assert len(results) == 1
        
    def test_dynamic_weight_adjustment(self, ensemble):
        """Test dynamic weight adjustment based on performance."""
        # Simulate detector performance history
        performance_history = {
            "anomaly": [0.90, 0.92, 0.88, 0.91],  # High accuracy
            "trend": [0.75, 0.73, 0.77, 0.74],    # Medium accuracy
            "pattern": [0.60, 0.58, 0.62, 0.59]    # Low accuracy
        }
        
        ensemble.update_weights(performance_history)
        
        # Weights should be adjusted based on performance
        weights = ensemble.get_current_weights()
        assert weights["anomaly"] > weights["trend"] > weights["pattern"]
        
        # Sum should still be 1
        assert abs(sum(weights.values()) - 1.0) < 0.01
        
    def test_confidence_aggregation(self, ensemble):
        """Test different confidence aggregation methods."""
        detector_results = {
            "anomaly": {"confidence": 0.9},
            "trend": {"confidence": 0.7},
            "pattern": {"confidence": 0.8}
        }
        
        # Test weighted average
        weighted_conf = ensemble._aggregate_confidence(
            detector_results, 
            method="weighted_average"
        )
        expected = (0.9 * 0.4 + 0.7 * 0.35 + 0.8 * 0.25)
        assert abs(weighted_conf - expected) < 0.01
        
        # Test max confidence
        max_conf = ensemble._aggregate_confidence(
            detector_results,
            method="max"
        )
        assert max_conf == 0.9
        
        # Test min confidence
        min_conf = ensemble._aggregate_confidence(
            detector_results,
            method="min"
        )
        assert min_conf == 0.7
        
    def test_detector_failure_handling(self, ensemble, sample_data):
        """Test handling of detector failures."""
        # One detector fails
        ensemble.detectors['anomaly'].detect.side_effect = Exception("Detector failed")
        ensemble.detectors['trend'].detect.return_value = [
            {"date": sample_data['date'].iloc[10], "type": "spike", "confidence": 0.8}
        ]
        ensemble.detectors['pattern'].detect.return_value = [
            {"date": sample_data['date'].iloc[10], "type": "spike", "confidence": 0.75}
        ]
        
        # Should still work with remaining detectors
        results = ensemble.detect(sample_data)
        assert len(results) > 0
        
        # Should log the failure
        assert ensemble.get_detector_status()['anomaly'] == 'failed'


class TestFeedbackModels:
    """Test feedback processor models."""
    
    def test_feedback_type_enum(self):
        """Test FeedbackType enumeration."""
        assert FeedbackType.CORRECT.value == "correct"
        assert FeedbackType.FALSE_POSITIVE.value == "false_positive"
        assert FeedbackType.FALSE_NEGATIVE.value == "false_negative"
        assert FeedbackType.SEVERITY_ADJUSTMENT.value == "severity_adjustment"
        
    def test_user_feedback_creation(self):
        """Test UserFeedback creation."""
        feedback = UserFeedback(
            feedback_id="fb_123",
            user_id="user_456",
            detection_id="det_789",
            feedback_type=FeedbackType.FALSE_POSITIVE,
            timestamp=datetime.now(),
            metric_type="steps",
            detection_date=date.today(),
            comments="Not actually anomalous, was hiking",
            context={
                "activity": "hiking",
                "expected": True
            }
        )
        
        assert feedback.feedback_type == FeedbackType.FALSE_POSITIVE
        assert feedback.comments == "Not actually anomalous, was hiking"
        assert feedback.context["activity"] == "hiking"
        
    def test_feedback_impact_creation(self):
        """Test FeedbackImpact creation."""
        impact = FeedbackImpact(
            detector_name="anomaly_detector",
            parameter="threshold",
            old_value=3.0,
            new_value=3.5,
            impact_score=0.15,
            confidence=0.85
        )
        
        assert impact.parameter == "threshold"
        assert impact.new_value > impact.old_value
        assert impact.impact_score == 0.15
        
    def test_learning_update_creation(self):
        """Test LearningUpdate creation."""
        update = LearningUpdate(
            update_id="upd_123",
            timestamp=datetime.now(),
            feedback_count=50,
            impacts=[
                FeedbackImpact("detector1", "sensitivity", 0.8, 0.75, -0.05, 0.9)
            ],
            performance_before={"accuracy": 0.82, "precision": 0.78},
            performance_after={"accuracy": 0.85, "precision": 0.82},
            applied=True
        )
        
        assert update.feedback_count == 50
        assert len(update.impacts) == 1
        assert update.performance_after["accuracy"] > update.performance_before["accuracy"]


class TestFeedbackProcessor:
    """Test feedback processor functionality."""
    
    @pytest.fixture
    def processor(self):
        """Create feedback processor."""
        with patch('src.analytics.feedback_processor.db_manager'):
            return FeedbackProcessor()
    
    @pytest.fixture
    def sample_feedback(self):
        """Create sample feedback."""
        return [
            UserFeedback(
                feedback_id="fb_1",
                user_id="user_1",
                detection_id="det_1",
                feedback_type=FeedbackType.FALSE_POSITIVE,
                timestamp=datetime.now(),
                metric_type="steps",
                detection_date=date.today(),
                comments="Was moving furniture",
                context={"activity": "moving"}
            ),
            UserFeedback(
                feedback_id="fb_2",
                user_id="user_1",
                detection_id="det_2",
                feedback_type=FeedbackType.CORRECT,
                timestamp=datetime.now(),
                metric_type="heart_rate",
                detection_date=date.today() - timedelta(days=1)
            ),
            UserFeedback(
                feedback_id="fb_3",
                user_id="user_2",
                detection_id="det_3",
                feedback_type=FeedbackType.FALSE_NEGATIVE,
                timestamp=datetime.now(),
                metric_type="steps",
                detection_date=date.today() - timedelta(days=2),
                comments="Missed low activity day when sick"
            )
        ]
    
    def test_process_feedback(self, processor, sample_feedback):
        """Test processing user feedback."""
        with patch.object(processor, '_store_feedback'):
            for feedback in sample_feedback:
                result = processor.process_feedback(feedback)
                assert result is True
                
            # Check feedback statistics
            stats = processor.get_feedback_statistics()
            assert stats['total_feedback'] == 3
            assert stats['false_positive_rate'] > 0
            
    def test_analyze_feedback_patterns(self, processor, sample_feedback):
        """Test analyzing feedback patterns."""
        # Store feedback
        processor.feedback_history = sample_feedback
        
        patterns = processor.analyze_feedback_patterns(
            metric_type="steps",
            time_window=timedelta(days=7)
        )
        
        assert 'false_positive_contexts' in patterns
        assert 'common_activities' in patterns
        assert patterns['feedback_count'] == 2  # Two steps feedbacks
        
        # Should identify moving/activity as false positive context
        assert any('moving' in context.lower() 
                  for context in patterns['false_positive_contexts'])
        
    def test_calculate_detector_adjustments(self, processor):
        """Test calculating detector adjustments from feedback."""
        # Simulate feedback showing high false positive rate
        feedback_stats = {
            'total': 100,
            'false_positives': 30,
            'false_negatives': 5,
            'correct': 65
        }
        
        adjustments = processor.calculate_adjustments(
            detector_name="anomaly_detector",
            feedback_stats=feedback_stats,
            current_params={"threshold": 2.5, "sensitivity": 0.8}
        )
        
        # Should recommend increasing threshold to reduce false positives
        assert 'threshold' in adjustments
        assert adjustments['threshold']['new_value'] > 2.5
        assert adjustments['threshold']['reason'] == 'high_false_positive_rate'
        
    def test_apply_learning_updates(self, processor):
        """Test applying learning updates to detectors."""
        updates = [
            FeedbackImpact(
                detector_name="anomaly_detector",
                parameter="threshold",
                old_value=2.5,
                new_value=3.0,
                impact_score=0.2,
                confidence=0.85
            )
        ]
        
        with patch.object(processor, '_update_detector_config') as mock_update:
            learning_update = processor.apply_learning_updates(updates)
            
            assert isinstance(learning_update, LearningUpdate)
            assert len(learning_update.impacts) == 1
            assert learning_update.applied is True
            mock_update.assert_called_once()
            
    def test_feedback_validation(self, processor):
        """Test feedback validation."""
        # Valid feedback
        valid_feedback = UserFeedback(
            feedback_id="fb_valid",
            user_id="user_1",
            detection_id="det_1",
            feedback_type=FeedbackType.CORRECT,
            timestamp=datetime.now(),
            metric_type="steps",
            detection_date=date.today()
        )
        
        assert processor.validate_feedback(valid_feedback) is True
        
        # Invalid feedback (future date)
        invalid_feedback = UserFeedback(
            feedback_id="fb_invalid",
            user_id="user_1",
            detection_id="det_1",
            feedback_type=FeedbackType.CORRECT,
            timestamp=datetime.now(),
            metric_type="steps",
            detection_date=date.today() + timedelta(days=1)
        )
        
        assert processor.validate_feedback(invalid_feedback) is False
        
    def test_feedback_aggregation(self, processor):
        """Test aggregating feedback over time."""
        # Create feedback over multiple days
        feedback_list = []
        for i in range(30):
            fb_type = np.random.choice([
                FeedbackType.CORRECT,
                FeedbackType.FALSE_POSITIVE,
                FeedbackType.FALSE_NEGATIVE
            ], p=[0.7, 0.2, 0.1])
            
            feedback_list.append(UserFeedback(
                feedback_id=f"fb_{i}",
                user_id="user_1",
                detection_id=f"det_{i}",
                feedback_type=fb_type,
                timestamp=datetime.now() - timedelta(days=i),
                metric_type="steps",
                detection_date=date.today() - timedelta(days=i)
            ))
        
        processor.feedback_history = feedback_list
        
        # Aggregate by week
        weekly_stats = processor.aggregate_feedback(
            group_by="week",
            metric_type="steps"
        )
        
        assert len(weekly_stats) > 0
        assert all('accuracy' in week for week in weekly_stats.values())
        
    def test_contextual_learning(self, processor):
        """Test learning from contextual patterns."""
        # Create feedback with context patterns
        contexts = [
            {"activity": "running", "weather": "rain"},
            {"activity": "running", "weather": "sunny"},
            {"activity": "hiking", "terrain": "mountain"},
            {"activity": "walking", "location": "mall"}
        ]
        
        feedback_with_context = []
        for i, context in enumerate(contexts):
            feedback_with_context.append(UserFeedback(
                feedback_id=f"fb_{i}",
                user_id="user_1",
                detection_id=f"det_{i}",
                feedback_type=FeedbackType.FALSE_POSITIVE,
                timestamp=datetime.now(),
                metric_type="steps",
                detection_date=date.today(),
                context=context
            ))
        
        patterns = processor.learn_contextual_patterns(
            feedback_with_context,
            min_support=2
        )
        
        # Should identify running as a common false positive context
        assert 'activity:running' in patterns
        assert patterns['activity:running']['count'] == 2
        assert patterns['activity:running']['confidence'] > 0


def test_ensemble_feedback_integration():
    """Test integration of ensemble detector with feedback processor."""
    # Create components
    detectors = {
        "anomaly": Mock(name="anomaly_detector"),
        "trend": Mock(name="trend_detector")
    }
    
    ensemble_config = EnsembleConfig(
        voting_strategy=VotingStrategy.WEIGHTED,
        detector_weights={"anomaly": 0.6, "trend": 0.4}
    )
    
    ensemble = EnsembleDetector(detectors=detectors, config=ensemble_config)
    
    with patch('src.analytics.feedback_processor.db_manager'):
        feedback_processor = FeedbackProcessor()
    
    # Simulate detection and feedback cycle
    # 1. Make detections
    sample_data = pd.DataFrame({
        'date': pd.date_range('2023-01-01', periods=30),
        'value': np.random.normal(8000, 1000, 30)
    })
    sample_data.iloc[15, 1] = 15000  # Anomaly
    
    detectors['anomaly'].detect.return_value = [
        {"date": sample_data['date'].iloc[15], 
         "type": "spike", 
         "confidence": 0.9,
         "detector": "anomaly"}
    ]
    detectors['trend'].detect.return_value = [
        {"date": sample_data['date'].iloc[15], 
         "type": "spike", 
         "confidence": 0.7,
         "detector": "trend"}
    ]
    
    detections = ensemble.detect(sample_data)
    assert len(detections) == 1
    
    # 2. User provides feedback
    user_feedback = UserFeedback(
        feedback_id="fb_test",
        user_id="user_1",
        detection_id=detections[0].get('id', 'det_1'),
        feedback_type=FeedbackType.FALSE_POSITIVE,
        timestamp=datetime.now(),
        metric_type="steps",
        detection_date=sample_data['date'].iloc[15],
        comments="Was at a marathon"
    )
    
    feedback_processor.process_feedback(user_feedback)
    
    # 3. Calculate adjustments
    feedback_stats = {
        'total': 10,
        'false_positives': 4,
        'false_negatives': 1,
        'correct': 5
    }
    
    adjustments = feedback_processor.calculate_adjustments(
        detector_name="anomaly",
        feedback_stats=feedback_stats,
        current_params={"threshold": 3.0}
    )
    
    # 4. Update ensemble weights based on performance
    detector_performance = {
        "anomaly": [0.6, 0.65, 0.62],  # Declining due to false positives
        "trend": [0.75, 0.77, 0.78]     # Improving
    }
    
    ensemble.update_weights(detector_performance)
    new_weights = ensemble.get_current_weights()
    
    # Trend detector should have higher weight now
    assert new_weights["trend"] > new_weights["anomaly"]
    
    # 5. Apply learning updates
    updates = [
        FeedbackImpact(
            detector_name="anomaly",
            parameter="threshold",
            old_value=3.0,
            new_value=adjustments['threshold']['new_value'],
            impact_score=0.1,
            confidence=0.8
        )
    ]
    
    learning_update = feedback_processor.apply_learning_updates(updates)
    assert learning_update.applied is True